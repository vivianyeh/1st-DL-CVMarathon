{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder(categories='auto')\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 1.4057 - acc: 0.5101\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.9566 - acc: 0.6611\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.7905 - acc: 0.7229\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.6614 - acc: 0.7675\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.5389 - acc: 0.8124\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.4121 - acc: 0.8556\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.3115 - acc: 0.8927\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.2260 - acc: 0.9232\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.1664 - acc: 0.9428\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.1353 - acc: 0.9539\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1287 - acc: 0.9557\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1063 - acc: 0.9628\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0921 - acc: 0.9680\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0873 - acc: 0.9700\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0703 - acc: 0.9761\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.0685 - acc: 0.9772\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.0711 - acc: 0.9761\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0699 - acc: 0.9765\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0594 - acc: 0.9793\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0543 - acc: 0.9819\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0494 - acc: 0.9836\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.0561 - acc: 0.9817\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0519 - acc: 0.9832\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0464 - acc: 0.9842\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0356 - acc: 0.9886\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0457 - acc: 0.9853\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.0597 - acc: 0.9804\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.0548 - acc: 0.9813\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0308 - acc: 0.9898\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.0254 - acc: 0.9914\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.0355 - acc: 0.9880\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.0392 - acc: 0.9867\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.0419 - acc: 0.9864\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.0386 - acc: 0.9871\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.0270 - acc: 0.9912\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.0306 - acc: 0.9904\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.0393 - acc: 0.9875\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.0361 - acc: 0.9882\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 0.0270 - acc: 0.9910\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 0.0329 - acc: 0.9895\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.0291 - acc: 0.9911\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.0317 - acc: 0.9895\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.0324 - acc: 0.9896\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.0182 - acc: 0.9940\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.0231 - acc: 0.9923\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.0230 - acc: 0.9925\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.0288 - acc: 0.99071s - lo\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.0302 - acc: 0.9900\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.0268 - acc: 0.9916\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.0294 - acc: 0.9910\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.0274 - acc: 0.9918\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 0.0166 - acc: 0.9944\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.0238 - acc: 0.9923\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0229 - acc: 0.9926\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0262 - acc: 0.9919\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0226 - acc: 0.9925\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.0198 - acc: 0.9937\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.0218 - acc: 0.9929\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0238 - acc: 0.9925\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0231 - acc: 0.9926\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0227 - acc: 0.9929\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0173 - acc: 0.9945\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.0187 - acc: 0.9938\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.0202 - acc: 0.9936\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0137 - acc: 0.9953\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0277 - acc: 0.9915\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0198 - acc: 0.9934\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0187 - acc: 0.9940\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.0139 - acc: 0.9955\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.0231 - acc: 0.9934\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0194 - acc: 0.9941\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0175 - acc: 0.9943\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0168 - acc: 0.9944\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.0150 - acc: 0.9952\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.0165 - acc: 0.9946\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0203 - acc: 0.9933\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0135 - acc: 0.9954\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0169 - acc: 0.9944\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0106 - acc: 0.9963\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0140 - acc: 0.9958\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.0217 - acc: 0.9930\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0190 - acc: 0.9943\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0151 - acc: 0.9953\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0155 - acc: 0.9952\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.0131 - acc: 0.9958\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0159 - acc: 0.9950\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.0159 - acc: 0.9950\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0137 - acc: 0.9958\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0142 - acc: 0.9957\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0128 - acc: 0.9963\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0135 - acc: 0.9957\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.0205 - acc: 0.9941\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.0173 - acc: 0.9947\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0180 - acc: 0.9950\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0100 - acc: 0.9970\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.0090 - acc: 0.9974\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0120 - acc: 0.9963\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0146 - acc: 0.9958\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.0116 - acc: 0.9964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c5ff840f60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(Convolution2D(32,kernel_size=(3,3),input_shape=(32,32,3),activation='relu', padding = 'SAME'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,kernel_size=(3,3),input_shape=(32,32,3),activation='relu', padding = 'SAME'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(activation=\"relu\", units=100)) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(activation=\"softmax\", units=10))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.9916683e-01, 4.5193663e-15, 1.3894260e-01, 1.6173224e-01,\n",
       "        7.9431439e-09, 8.1049554e-20, 6.4695339e-11, 7.4610448e-15,\n",
       "        1.5835201e-04, 5.8552488e-18]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 123us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.6246087682723998, 0.649]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
